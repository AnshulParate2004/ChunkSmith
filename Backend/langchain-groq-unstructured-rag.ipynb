{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77e4616-c43b-42d4-88bf-40eeaab5e6cf",
   "metadata": {},
   "source": [
    "# Build Your Own Retrieval Augmented Generation (RAG) Bot\n",
    "\n",
    "### [Youtube video covering this notebook](https://youtu.be/m_3q3XnLlTI?si=rI9mCpNcYpVB5jZF)\n",
    "\n",
    "## Tech used\n",
    "- LangChain [link](https://www.langchain.com/)\n",
    "- Unstructured [link](https://unstructured.io/)\n",
    "- LangSmith [link](https://smith.langchain.com/)\n",
    "- Qdrant Cloud [link](https://cloud.qdrant.io)\n",
    "- Groq API [link](https://console.groq.com/playground)\n",
    "- Llama3 via Groq API\n",
    "- Fastembed [link](https://github.com/qdrant/fastembed)\n",
    "\n",
    "## File type used\n",
    "- PDF\n",
    "- Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f9ec6-b56b-444c-9d9f-6f0b39973450",
   "metadata": {},
   "source": [
    "### Some important links\n",
    "- https://unstructured.io/\n",
    "- https://unstructured-io.github.io/unstructured/index.html\n",
    "- https://docs.unstructured.io/api-reference/api-services/python-sdk\n",
    "- https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b549f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2454abe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[all-docs]\n",
      "  Using cached unstructured-0.18.15-py3-none-any.whl (1.8 MB)\n",
      "Requirement already satisfied: unstructured-client in d:\\multimodulrag\\venv\\lib\\site-packages (0.42.3)\n",
      "Collecting watermark\n",
      "  Using cached watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting langchain-groq\n",
      "  Using cached langchain_groq-1.0.0-py3-none-any.whl (16 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-1.0.1-py3-none-any.whl (106 kB)\n",
      "Collecting fastembed\n",
      "  Using cached fastembed-0.7.3-py3-none-any.whl (105 kB)\n",
      "Collecting qdrant_client\n",
      "  Using cached qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
      "Requirement already satisfied: python-dotenv in d:\\multimodulrag\\venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.4.4)\n",
      "Requirement already satisfied: filetype in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: lxml in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (6.0.2)\n",
      "Requirement already satisfied: nltk in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.9.2)\n",
      "Requirement already satisfied: requests in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (4.14.2)\n",
      "Requirement already satisfied: emoji in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.15.0)\n",
      "Collecting dataclasses-json\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: python-iso639 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: numpy in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.2.6)\n",
      "Requirement already satisfied: rapidfuzz in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.14.1)\n",
      "Requirement already satisfied: backoff in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (4.15.0)\n",
      "Requirement already satisfied: wrapt in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.17.3)\n",
      "Requirement already satisfied: tqdm in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (7.1.1)\n",
      "Requirement already satisfied: python-oxmsg in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.1)\n",
      "Requirement already satisfied: networkx in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.5)\n",
      "Requirement already satisfied: pypandoc in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.15)\n",
      "Collecting effdet\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (0.3.15)\n",
      "Requirement already satisfied: xlrd in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.0.2)\n",
      "Requirement already satisfied: markdown in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.9)\n",
      "Collecting msoffcrypto-tool\n",
      "  Using cached msoffcrypto_tool-5.4.2-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: python-pptx>=1.0.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.0.2)\n",
      "Requirement already satisfied: pi-heif in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.1.1)\n",
      "Requirement already satisfied: pdf2image in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: pandas in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (2.3.3)\n",
      "Requirement already satisfied: pypdf in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (6.1.2)\n",
      "Collecting google-cloud-vision\n",
      "  Using cached google_cloud_vision-3.11.0-py3-none-any.whl (529 kB)\n",
      "Collecting onnx>=1.17.0\n",
      "  Using cached onnx-1.19.1-cp311-cp311-win_amd64.whl (16.5 MB)\n",
      "Requirement already satisfied: python-docx>=1.1.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Collecting unstructured-inference>=1.0.5\n",
      "  Using cached unstructured_inference-1.0.5-py3-none-any.whl (48 kB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: openpyxl in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (3.1.5)\n",
      "Requirement already satisfied: pikepdf in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured[all-docs]) (9.11.0)\n",
      "Collecting onnxruntime>=1.19.0\n",
      "  Using cached onnxruntime-1.23.1-cp311-cp311-win_amd64.whl (13.5 MB)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (25.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (46.0.3)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (2.12.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-client) (1.0.0)\n",
      "Requirement already satisfied: ipython>=6.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from watermark) (9.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in d:\\multimodulrag\\venv\\lib\\site-packages (from watermark) (8.7.0)\n",
      "Requirement already satisfied: setuptools in d:\\multimodulrag\\venv\\lib\\site-packages (from watermark) (65.5.0)\n",
      "Collecting groq<1.0.0,>=0.30.0\n",
      "  Using cached groq-0.32.0-py3-none-any.whl (135 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0\n",
      "  Using cached langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0\n",
      "  Using cached langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.20\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from fastembed) (0.7.3)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from fastembed) (5.2.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from fastembed) (11.3.0)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from fastembed) (0.1.5)\n",
      "Collecting tokenizers<1.0,>=0.15\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from qdrant_client) (1.75.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from qdrant_client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from qdrant_client) (6.33.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in d:\\multimodulrag\\venv\\lib\\site-packages (from qdrant_client) (2.5.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client) (2.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: sniffio in d:\\multimodulrag\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: certifi in d:\\multimodulrag\\venv\\lib\\site-packages (from httpcore>=1.0.9->unstructured-client) (2025.10.5)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\multimodulrag\\venv\\lib\\site-packages (from httpcore>=1.0.9->unstructured-client) (0.16.0)\n",
      "Requirement already satisfied: idna in d:\\multimodulrag\\venv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (3.11)\n",
      "Collecting h2<5,>=3\n",
      "  Using cached h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: filelock in d:\\multimodulrag\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\multimodulrag\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.3)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\multimodulrag\\venv\\lib\\site-packages (from importlib-metadata>=1.4->watermark) (3.23.0)\n",
      "Requirement already satisfied: colorama in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from ipython>=6.0->watermark) (5.14.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45\n",
      "  Using cached langsmith-0.4.37-py3-none-any.whl (396 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (9.1.2)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0\n",
      "  Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed) (1.2.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from onnx>=1.17.0->unstructured[all-docs]) (0.5.3)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: flatbuffers in d:\\multimodulrag\\venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (25.9.23)\n",
      "Requirement already satisfied: sympy in d:\\multimodulrag\\venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (1.14.0)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\multimodulrag\\venv\\lib\\site-packages (from portalocker<4.0,>=2.7.0->qdrant_client) (311)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\multimodulrag\\venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client) (0.4.2)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in d:\\multimodulrag\\venv\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.2.9)\n",
      "Requirement already satisfied: python-multipart in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (0.0.20)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (4.12.0.88)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp311-cp311-win_amd64.whl (109.3 MB)\n",
      "Collecting timm\n",
      "  Using cached timm-1.0.20-py3-none-any.whl (2.5 MB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Requirement already satisfied: scipy in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (1.16.2)\n",
      "Requirement already satisfied: pypdfium2 in d:\\multimodulrag\\venv\\lib\\site-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (4.30.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from beautifulsoup4->unstructured[all-docs]) (2.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.0.10)\n",
      "Requirement already satisfied: omegaconf>=2.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1\n",
      "  Using cached google_api_core-2.26.0-py3-none-any.whl (162 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1\n",
      "  Using cached google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\multimodulrag\\venv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (1.26.1)\n",
      "Requirement already satisfied: six>=1.9 in d:\\multimodulrag\\venv\\lib\\site-packages (from html5lib->unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in d:\\multimodulrag\\venv\\lib\\site-packages (from html5lib->unstructured[all-docs]) (0.5.1)\n",
      "Requirement already satisfied: olefile>=0.46 in d:\\multimodulrag\\venv\\lib\\site-packages (from msoffcrypto-tool->unstructured[all-docs]) (0.47)\n",
      "Requirement already satisfied: click in d:\\multimodulrag\\venv\\lib\\site-packages (from nltk->unstructured[all-docs]) (8.3.0)\n",
      "Requirement already satisfied: joblib in d:\\multimodulrag\\venv\\lib\\site-packages (from nltk->unstructured[all-docs]) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\multimodulrag\\venv\\lib\\site-packages (from nltk->unstructured[all-docs]) (2025.9.18)\n",
      "Requirement already satisfied: et-xmlfile in d:\\multimodulrag\\venv\\lib\\site-packages (from openpyxl->unstructured[all-docs]) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\multimodulrag\\venv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\multimodulrag\\venv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2025.2)\n",
      "Requirement already satisfied: Deprecated in d:\\multimodulrag\\venv\\lib\\site-packages (from pikepdf->unstructured[all-docs]) (1.2.18)\n",
      "Requirement already satisfied: pycparser in d:\\multimodulrag\\venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=3.1->unstructured-client) (2.23)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\multimodulrag\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from h2<5,>=3->httpx>=0.27.0->unstructured-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from h2<5,>=3->httpx>=0.27.0->unstructured-client) (4.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\multimodulrag\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\multimodulrag\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in d:\\multimodulrag\\venv\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: wcwidth in d:\\multimodulrag\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.2.14)\n",
      "Requirement already satisfied: safetensors in d:\\multimodulrag\\venv\\lib\\site-packages (from timm->unstructured-inference>=1.0.5->unstructured[all-docs]) (0.6.2)\n",
      "Requirement already satisfied: jinja2 in d:\\multimodulrag\\venv\\lib\\site-packages (from torch->unstructured-inference>=1.0.5->unstructured[all-docs]) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from sympy->onnxruntime>=1.19.0->unstructured[all-docs]) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs]) (10.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\multimodulrag\\venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\multimodulrag\\venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (3.2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.0->watermark) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.0->watermark) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\multimodulrag\\venv\\lib\\site-packages (from stack_data->ipython>=6.0->watermark) (0.2.3)\n",
      "Requirement already satisfied: pyreadline3 in d:\\multimodulrag\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs]) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\multimodulrag\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\multimodulrag\\venv\\lib\\site-packages (from jinja2->torch->unstructured-inference>=1.0.5->unstructured[all-docs]) (3.0.3)\n",
      "Installing collected packages: h2, googleapis-common-protos, contourpy, torch, onnx, matplotlib, huggingface-hub, grpcio-status, google-auth, dataclasses-json, coloredlogs, watermark, torchvision, tokenizers, pdfminer.six, onnxruntime, msoffcrypto-tool, langsmith, langgraph-sdk, groq, google-api-core, accelerate, unstructured, transformers, timm, qdrant_client, langchain-core, fastembed, unstructured-inference, langgraph-checkpoint, langchain-groq, google-cloud-vision, effdet, langgraph-prebuilt, langgraph, langchain\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'd:\\\\MultiModulRag\\\\venv\\\\Lib\\\\site-packages\\\\transformers\\\\models\\\\clip\\\\tokenization_clip.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "%pip install \"unstructured[all-docs]\" unstructured-client watermark langchain-groq langchain fastembed qdrant_client python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44c93749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30697566-ee92-47f1-a8eb-c17848e9a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a2cac-7bc8-4cd8-ae26-3d1076e8384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc87392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain, groq, fastembed, qdrant_client, unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a74718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastembed    : 0.7.3\n",
      "qdrant_client: 1.15.1\n",
      "langchain    : 1.0.1\n",
      "unstructured : 0.18.15\n",
      "groq         : 0.32.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured.partition in unstructured:\n",
      "\n",
      "NAME\n",
      "    unstructured.partition\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    auto\n",
      "    common (package)\n",
      "    csv\n",
      "    doc\n",
      "    docx\n",
      "    email\n",
      "    epub\n",
      "    html (package)\n",
      "    image\n",
      "    json\n",
      "    md\n",
      "    model_init\n",
      "    msg\n",
      "    ndjson\n",
      "    odt\n",
      "    org\n",
      "    pdf\n",
      "    pdf_image (package)\n",
      "    ppt\n",
      "    pptx\n",
      "    rst\n",
      "    rtf\n",
      "    strategies\n",
      "    text\n",
      "    text_type\n",
      "    tsv\n",
      "    utils (package)\n",
      "    xlsx\n",
      "    xml\n",
      "\n",
      "FILE\n",
      "    d:\\multimodulrag\\venv\\lib\\site-packages\\unstructured\\partition\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unstructured.partition\n",
    "\n",
    "help(unstructured.partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76132dfe-7360-4147-a5b1-0e571917e08b",
   "metadata": {},
   "source": [
    "## Preprocess the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be519e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "partition_pdf(\n",
      "    filename: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    file: \u001b[33m'Optional[IO[bytes]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_page_breaks: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    strategy: \u001b[33m'str'\u001b[39m = \u001b[33m'auto'\u001b[39m,\n",
      "    infer_table_structure: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ocr_languages: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    languages: \u001b[33m'Optional[list[str]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    detect_language_per_element: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    metadata_last_modified: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunking_strategy: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    hi_res_model_name: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_images_in_pdf: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    extract_image_block_types: \u001b[33m'Optional[list[str]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_output_dir: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_to_payload: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    starting_page_number: \u001b[33m'int'\u001b[39m = \u001b[32m1\u001b[39m,\n",
      "    extract_forms: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    form_extraction_skip_tables: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    password: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_char_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_overlap: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_word_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[32m0.185\u001b[39m,\n",
      "    **kwargs: \u001b[33m'Any'\u001b[39m,\n",
      ") -> \u001b[33m'list[Element]'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Parses a pdf document into a list of interpreted elements.\n",
      "    Parameters\n",
      "    ----------\n",
      "    filename\n",
      "        A string defining the target filename path.\n",
      "    file\n",
      "        A file-like object as bytes --> open(filename, \"rb\").\n",
      "    strategy\n",
      "        The strategy to use for partitioning the PDF. Valid strategies are \"hi_res\",\n",
      "        \"ocr_only\", and \"fast\". When using the \"hi_res\" strategy, the function uses\n",
      "        a layout detection model to identify document elements. When using the\n",
      "        \"ocr_only\" strategy, partition_pdf simply extracts the text from the\n",
      "        document using OCR and processes it. If the \"fast\" strategy is used, the text\n",
      "        is extracted directly from the PDF. The default strategy `auto` will determine\n",
      "        when a page can be extracted using `fast` mode, otherwise it will fall back to `hi_res`.\n",
      "    infer_table_structure\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, any Table elements that are extracted will also have a metadata field\n",
      "        named \"text_as_html\" where the table's text content is rendered into an html string.\n",
      "        I.e., rows and cells are preserved.\n",
      "        Whether True or False, the \"text\" field is always present in any Table element\n",
      "        and is the text content of the table (no structure).\n",
      "    languages\n",
      "        The languages present in the document, for use in partitioning and/or OCR. To use a language\n",
      "        with Tesseract, you'll first need to install the appropriate Tesseract language pack.\n",
      "    metadata_last_modified\n",
      "        The last modified date for the document.\n",
      "    hi_res_model_name\n",
      "        The layout detection model used when partitioning strategy is set to `hi_res`.\n",
      "    extract_images_in_pdf\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, any detected images will be saved in the path specified by\n",
      "        'extract_image_block_output_dir' or stored as base64 encoded data within metadata fields.\n",
      "        Deprecation Note: This parameter is marked for deprecation. Future versions will use\n",
      "        'extract_image_block_types' for broader extraction capabilities.\n",
      "    extract_image_block_types\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        Images of the element type(s) specified in this list (e.g., [\"Image\", \"Table\"]) will be\n",
      "        saved in the path specified by 'extract_image_block_output_dir' or stored as base64\n",
      "        encoded data within metadata fields.\n",
      "    extract_image_block_to_payload\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, images of the element type(s) defined in 'extract_image_block_types' will be\n",
      "        encoded as base64 data and stored in two metadata fields: 'image_base64' and\n",
      "        'image_mime_type'.\n",
      "        This parameter facilitates the inclusion of element data directly within the payload,\n",
      "        especially for web-based applications or APIs.\n",
      "    extract_image_block_output_dir\n",
      "        Only applicable if `strategy=hi_res` and `extract_image_block_to_payload=False`.\n",
      "        The filesystem path for saving images of the element type(s)\n",
      "        specified in 'extract_image_block_types'.\n",
      "    extract_forms\n",
      "        Whether the form extraction logic should be run\n",
      "        (results in adding FormKeysValues elements to output).\n",
      "    form_extraction_skip_tables\n",
      "        Whether the form extraction logic should ignore regions designated as Tables.\n",
      "    pdfminer_line_margin\n",
      "        If two lines are close together they are considered to be part of the same paragraph.\n",
      "        The margin is specified relative to the height of a line.\n",
      "    pdfminer_char_margin\n",
      "        If two characters are closer together than this margin they are considered part of\n",
      "        the same line. The margin is specified relative to the width of the character.\n",
      "    pdfminer_line_overlap\n",
      "        If two characters have more overlap than this they are considered to be on the same line.\n",
      "        The overlap is specified relative to the minimum height of both characters.\n",
      "    pdfminer_word_margin\n",
      "        If two characters on the same line are further apart than this margin then they are\n",
      "        considered to be two separate words, and an intermediate space will be added for\n",
      "        readability. The margin is specified relative to the width of the character.\n",
      "    \n",
      "chunking_strategy\n",
      "        Strategy used for chunking text into larger or smaller elements.\n",
      "        Defaults to `None` with optional arg of 'basic' or 'by_title'.\n",
      "        Additional Parameters:\n",
      "                multipage_sections\n",
      "                        If True, sections can span multiple pages. Defaults to True.\n",
      "                combine_text_under_n_chars\n",
      "                        Combines elements (for example a series of titles) until a section\n",
      "                        reaches a length of n characters. Only applies to 'by_title' strategy.\n",
      "                new_after_n_chars\n",
      "                        Cuts off chunks once they reach a length of n characters; a soft max.\n",
      "                max_characters\n",
      "                        Chunks elements text and text_as_html (if present) into chunks\n",
      "                        of length n characters, a hard max.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "@apply_metadata(FileType.PDF)\n",
      "@add_chunking_strategy\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m partition_pdf(\n",
      "    filename: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    file: Optional[IO[bytes]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_page_breaks: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    strategy: str = PartitionStrategy.AUTO,\n",
      "    infer_table_structure: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ocr_languages: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# changing to optional for deprecation\u001b[39;00m\n",
      "    languages: Optional[list[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    detect_language_per_element: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    metadata_last_modified: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunking_strategy: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# used by decorator\u001b[39;00m\n",
      "    hi_res_model_name: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_images_in_pdf: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    extract_image_block_types: Optional[list[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_output_dir: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_to_payload: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    starting_page_number: int = \u001b[32m1\u001b[39m,\n",
      "    extract_forms: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    form_extraction_skip_tables: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    password: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_margin: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_char_margin: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_overlap: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_word_margin: Optional[float] = \u001b[32m0.185\u001b[39m,\n",
      "    **kwargs: Any,\n",
      ") -> list[Element]:\n",
      "    \u001b[33m\"\"\"Parses a pdf document into a list of interpreted elements.\u001b[39m\n",
      "\u001b[33m    Parameters\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    filename\u001b[39m\n",
      "\u001b[33m        A string defining the target filename path.\u001b[39m\n",
      "\u001b[33m    file\u001b[39m\n",
      "\u001b[33m        A file-like object as bytes --> open(filename, \"rb\").\u001b[39m\n",
      "\u001b[33m    strategy\u001b[39m\n",
      "\u001b[33m        The strategy to use for partitioning the PDF. Valid strategies are \"hi_res\",\u001b[39m\n",
      "\u001b[33m        \"ocr_only\", and \"fast\". When using the \"hi_res\" strategy, the function uses\u001b[39m\n",
      "\u001b[33m        a layout detection model to identify document elements. When using the\u001b[39m\n",
      "\u001b[33m        \"ocr_only\" strategy, partition_pdf simply extracts the text from the\u001b[39m\n",
      "\u001b[33m        document using OCR and processes it. If the \"fast\" strategy is used, the text\u001b[39m\n",
      "\u001b[33m        is extracted directly from the PDF. The default strategy `auto` will determine\u001b[39m\n",
      "\u001b[33m        when a page can be extracted using `fast` mode, otherwise it will fall back to `hi_res`.\u001b[39m\n",
      "\u001b[33m    infer_table_structure\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, any Table elements that are extracted will also have a metadata field\u001b[39m\n",
      "\u001b[33m        named \"text_as_html\" where the table's text content is rendered into an html string.\u001b[39m\n",
      "\u001b[33m        I.e., rows and cells are preserved.\u001b[39m\n",
      "\u001b[33m        Whether True or False, the \"text\" field is always present in any Table element\u001b[39m\n",
      "\u001b[33m        and is the text content of the table (no structure).\u001b[39m\n",
      "\u001b[33m    languages\u001b[39m\n",
      "\u001b[33m        The languages present in the document, for use in partitioning and/or OCR. To use a language\u001b[39m\n",
      "\u001b[33m        with Tesseract, you'll first need to install the appropriate Tesseract language pack.\u001b[39m\n",
      "\u001b[33m    metadata_last_modified\u001b[39m\n",
      "\u001b[33m        The last modified date for the document.\u001b[39m\n",
      "\u001b[33m    hi_res_model_name\u001b[39m\n",
      "\u001b[33m        The layout detection model used when partitioning strategy is set to `hi_res`.\u001b[39m\n",
      "\u001b[33m    extract_images_in_pdf\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, any detected images will be saved in the path specified by\u001b[39m\n",
      "\u001b[33m        'extract_image_block_output_dir' or stored as base64 encoded data within metadata fields.\u001b[39m\n",
      "\u001b[33m        Deprecation Note: This parameter is marked for deprecation. Future versions will use\u001b[39m\n",
      "\u001b[33m        'extract_image_block_types' for broader extraction capabilities.\u001b[39m\n",
      "\u001b[33m    extract_image_block_types\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        Images of the element type(s) specified in this list (e.g., [\"Image\", \"Table\"]) will be\u001b[39m\n",
      "\u001b[33m        saved in the path specified by 'extract_image_block_output_dir' or stored as base64\u001b[39m\n",
      "\u001b[33m        encoded data within metadata fields.\u001b[39m\n",
      "\u001b[33m    extract_image_block_to_payload\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, images of the element type(s) defined in 'extract_image_block_types' will be\u001b[39m\n",
      "\u001b[33m        encoded as base64 data and stored in two metadata fields: 'image_base64' and\u001b[39m\n",
      "\u001b[33m        'image_mime_type'.\u001b[39m\n",
      "\u001b[33m        This parameter facilitates the inclusion of element data directly within the payload,\u001b[39m\n",
      "\u001b[33m        especially for web-based applications or APIs.\u001b[39m\n",
      "\u001b[33m    extract_image_block_output_dir\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res` and `extract_image_block_to_payload=False`.\u001b[39m\n",
      "\u001b[33m        The filesystem path for saving images of the element type(s)\u001b[39m\n",
      "\u001b[33m        specified in 'extract_image_block_types'.\u001b[39m\n",
      "\u001b[33m    extract_forms\u001b[39m\n",
      "\u001b[33m        Whether the form extraction logic should be run\u001b[39m\n",
      "\u001b[33m        (results in adding FormKeysValues elements to output).\u001b[39m\n",
      "\u001b[33m    form_extraction_skip_tables\u001b[39m\n",
      "\u001b[33m        Whether the form extraction logic should ignore regions designated as Tables.\u001b[39m\n",
      "\u001b[33m    pdfminer_line_margin\u001b[39m\n",
      "\u001b[33m        If two lines are close together they are considered to be part of the same paragraph.\u001b[39m\n",
      "\u001b[33m        The margin is specified relative to the height of a line.\u001b[39m\n",
      "\u001b[33m    pdfminer_char_margin\u001b[39m\n",
      "\u001b[33m        If two characters are closer together than this margin they are considered part of\u001b[39m\n",
      "\u001b[33m        the same line. The margin is specified relative to the width of the character.\u001b[39m\n",
      "\u001b[33m    pdfminer_line_overlap\u001b[39m\n",
      "\u001b[33m        If two characters have more overlap than this they are considered to be on the same line.\u001b[39m\n",
      "\u001b[33m        The overlap is specified relative to the minimum height of both characters.\u001b[39m\n",
      "\u001b[33m    pdfminer_word_margin\u001b[39m\n",
      "\u001b[33m        If two characters on the same line are further apart than this margin then they are\u001b[39m\n",
      "\u001b[33m        considered to be two separate words, and an intermediate space will be added for\u001b[39m\n",
      "\u001b[33m        readability. The margin is specified relative to the width of the character.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    exactly_one(filename=filename, file=file)\n",
      "\n",
      "    languages = check_language_args(languages \u001b[38;5;28;01mor\u001b[39;00m [], ocr_languages)\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf_or_image(\n",
      "        filename=filename,\n",
      "        file=file,\n",
      "        include_page_breaks=include_page_breaks,\n",
      "        strategy=strategy,\n",
      "        infer_table_structure=infer_table_structure,\n",
      "        languages=languages,\n",
      "        detect_language_per_element=detect_language_per_element,\n",
      "        metadata_last_modified=metadata_last_modified,\n",
      "        hi_res_model_name=hi_res_model_name,\n",
      "        extract_images_in_pdf=extract_images_in_pdf,\n",
      "        extract_image_block_types=extract_image_block_types,\n",
      "        extract_image_block_output_dir=extract_image_block_output_dir,\n",
      "        extract_image_block_to_payload=extract_image_block_to_payload,\n",
      "        starting_page_number=starting_page_number,\n",
      "        extract_forms=extract_forms,\n",
      "        form_extraction_skip_tables=form_extraction_skip_tables,\n",
      "        password=password,\n",
      "        pdfminer_line_margin=pdfminer_line_margin,\n",
      "        pdfminer_char_margin=pdfminer_char_margin,\n",
      "        pdfminer_line_overlap=pdfminer_line_overlap,\n",
      "        pdfminer_word_margin=pdfminer_word_margin,\n",
      "        **kwargs,\n",
      "    )\n",
      "\u001b[31mFile:\u001b[39m      d:\\multimodulrag\\venv\\lib\\site-packages\\unstructured\\partition\\pdf.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "partition_pdf??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b75d977-7d80-427d-9b24-4fcf1384fc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = r\"D:\\MultiModulRag\\docs\\NIPS-2017-attention-is-all-you-need-Paper.pdf\"\n",
    "#path = \"images\"\n",
    "\n",
    "# Extract images, tables, and chunk text\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,\n",
    "    extract_images_in_pdf=False,\n",
    "    strategy = \"hi_res\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=3000,\n",
    "    #new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=200,\n",
    "    #extract_image_block_output_dir=path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b035bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 24}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CompositeElement'}\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cda6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 48}\n",
      "{'CompositeElement'}\n"
     ]
    }
   ],
   "source": [
    "# Extract images, tables, and chunk text\n",
    "path = r\"D:\\MultiModulRag\\Backend\\output\\images\\groq\"\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,\n",
    "    extract_images_in_pdf=True,\n",
    "    strategy = \"hi_res\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=3000,\n",
    "    extract_image_block_types=[\"Image\"],\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=200,\n",
    "    extract_image_block_output_dir=path,\n",
    ")\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "print(category_counts)\n",
    "\n",
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed8e92e-5d85-4d9e-9867-6ed8a190b9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': '3a5e68b361dc8794d9341af4d9b4f022',\n",
       " 'text': 'Illia Polosukhin \\n\\nillia.polosukhin@gmail.com\\n\\nAbstract\\n\\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signicantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-10-20T15:54:36',\n",
       "  'page_number': 1,\n",
       "  'orig_elements': 'eJy9lt1u3DYQhV9loOuVIFH/vmoKuEGBpjXQDXLhGAtKHK2IUOKGpLzeBn33DKm1kSbbojBgX8kccWbOnI/U+vZLhAonnN1OiugKopRjwUss4541fVwMFYv5MIi45F0p+lTkosyiDUQTOi6445TzJeq1NkLO3KENa8VPenG7EeV+dBRhLE0p5xw+SuFGimZ1iB60nJ3Pu72tiyqpN1C3acLuNvC4bliWVH7dVnlS/rhe91MgsifrcPJz3MgHVH8eeI/R3/RCoMPeST3vesWt3R2M7mhbmpRpVee0YZAK3emAIffmXRTkzvuF78NMtxHO++guRK3bTVrIQWJwjKWsjLM0Zuk2K6/K4iqvfPaBMnfzMnVo/KxehMMH70b0q1KSw41W2i6fRjl/XBjLaqBHyoK5j0K20qmg/3tKWcXyruB1XIqcKDWcxR0v87hpm7RL0yJtCv5ilKqySBpPoVgpPK5LluR+naWErboUCBnP5JRXbfnKnKTnlByeOP20n7hUSa+nbyH9zo3hTt7j1qddgMWKjPOhTOOqrzEuMK89rCIeRCZEXzYFY+LlrlTTJGwDbV6cr9R5XdVJGa5QxpL2wjrsfx6qpszK4pVRvemsM7x3/+v2DJVgddEVcZfxNC6KlL5xZVbFdKXKPKWPDuvrFwOSt62/Cy09Wm/4eZ3lbbYSynJCkF2KrDnPg9LSaNkrQ9mOCEJPZNrswOLnBecegTjNVixBJVADVBa4Qei4RQEUo/t1UPgABvvFGMIG2lBwvtdq8UlcwYyLCQ931OaTBTdyB3Lu1SIQ+AzUiAob+lMAB4FhlYAX1KF1cEAzaEPK9k8KlNW+yUz2UTn8R4lzAYobvexH34E7R8rCCNiPfJZ2SuADAhl+0JZEkLgjWOlHedRJY/aj9IAWg5vQZevN8FLQbM4OWK1QnbwRF3rYDQhpDzhbr/0o3fhkU49B6zdGWfDphqolcP1AM0t/CawvTXpg4qRmPgNRPDRy3JKddtRHL4/mONvjNBkHdvFFiIac4fPClXQnOI50oujl6iVxPHBCQyPIv3inVk2G2Evjd1i5n+XHZejSrKdTQXMqtFSelPkeJEXOCfyxmLUxeIl4jxZYkxTw82/X74N6cu7Duy2wNCvget4raceY8uO3aCaC8/1EGyAORt97Bfo+gCTAD9I6HwknwqBdlCN711Pk42QyTjQCBbvTmseCBBL4LxpIwi8exXhBgn4aivqRNbSf5no8J1QA4/U1vXUY6yGmFjE3bh3b9t5cPUCRJSnwwfkxvF1eKp0goH+FQPBTwBs+SvD25j1p52AnAgKD/z56OVTDi39K7rX1h2KNBjPO0AejpxAk0Ei/cXRqk//45bv7CoO/RS0=',\n",
       "  'file_directory': 'D:\\\\MultiModulRag\\\\docs',\n",
       "  'filename': 'NIPS-2017-attention-is-all-you-need-Paper.pdf'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50942e5-33e4-43d9-ad89-a3840a944ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = [el for el in pdf_elements if el.category == \"Table\"]\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733c9d8-d6a5-4bad-8ba0-b1393165b6e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m table_html = \u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.metadata.text_as_html()\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "table_html = tables[0].metadata.text_as_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27481fdb-e8d1-430d-8919-46205765c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Layer Type</th>\n",
      "      <th>Complexity per Layer</th>\n",
      "      <th>Sequential Operations</th>\n",
      "      <th>Maximum Path Length</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>Self-Attention</td>\n",
      "      <td>O(n? - d)</td>\n",
      "      <td>O(1)</td>\n",
      "      <td>O(1)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Recurrent</td>\n",
      "      <td>O(n-d?)</td>\n",
      "      <td>O(n)</td>\n",
      "      <td>O(n)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Convolutional</td>\n",
      "      <td>O(k-n-d?)</td>\n",
      "      <td>olny</td>\n",
      "      <td>O(logx(n))</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Self-Attention (restricted)</td>\n",
      "      <td>O(r-n-d)</td>\n",
      "      <td>ol)</td>\n",
      "      <td>O(n/r)</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "print(etree.tostring(tree, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ffd80c89-5c09-4b89-b36b-9017d334499a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the element with text \"References\" and category \"Title\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m reference_title = \u001b[43m[\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpdf_elements\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReferences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Find the element with text \"References\" and category \"Title\"\n",
    "reference_title = [\n",
    "    el for el in pdf_elements\n",
    "    if el.text == \"References\"\n",
    "    and el.category == \"Title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c16d2b4-2039-4f08-ac63-9a4f27d0bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': '89beabec90ed5c180a6f9323a7fa5cf4',\n",
       " 'text': 'References',\n",
       " 'metadata': {'detection_class_prob': 0.8838503956794739,\n",
       "  'coordinates': {'points': ((np.float64(299.9165344238281),\n",
       "     np.float64(201.40676888888876)),\n",
       "    (np.float64(299.9165344238281), np.float64(234.61565777777764)),\n",
       "    (np.float64(457.28265380859375), np.float64(234.61565777777764)),\n",
       "    (np.float64(457.28265380859375), np.float64(201.40676888888876))),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1700,\n",
       "   'layout_height': 2200},\n",
       "  'last_modified': '2025-10-20T15:54:36',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 10,\n",
       "  'file_directory': 'D:\\\\MultiModulRag\\\\docs',\n",
       "  'filename': 'NIPS-2017-attention-is-all-you-need-Paper.pdf'}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_title.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "303b9220-6367-4acc-a301-72e90620ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ID of the reference title element\n",
    "references_id = reference_title.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b1b9656-0018-4936-a9c9-3beac7a7c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in pdf_elements:\n",
    "    if element.metadata.parent_id == references_id:\n",
    "        print(element)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7c9c2ce-433c-493f-8d01-3d257bf1eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out elements with a parent_id matching references_id\n",
    "pdf_elements = [el for el in pdf_elements if el.metadata.parent_id != references_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3495de3-1ad8-4f81-b979-d67de01bd8d2",
   "metadata": {},
   "source": [
    "### Filter out headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29593c8d-a579-454f-872f-9001caa5613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [el for el in pdf_elements if el.category == \"Header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d7e6a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e2a006f-9125-4c13-a2ee-a86452b59b2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mheaders\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.to_dict()\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "headers[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c40d66a-4be5-4051-8226-5be421118ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out elements from the `pdf_elements` list that have the category \"Header\".\n",
    "pdf_elements = [el for el in pdf_elements if el.category != \"Header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b88af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81dcbbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': '5e6dd3e3a8b20747a9afd1979fe37fff',\n",
       " 'text': '3.3 Position-wise Feed-Forward Networks\\n\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.\\n\\nFFN(x) = max(0,xW1 + b1)W2 + b2 (2)\\n\\nWhile the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality dff = 2048.',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-10-20T15:54:36',\n",
       "  'page_number': 5,\n",
       "  'orig_elements': 'eJy9VU1v4zYQ/SsDnRLUFERK1EeAPewlQIE2CNoUOQSBQYkji1iZMkg6trvof+9QSnaDrbuHAIkvlh755oNv+PTwNcERt2jD2ujkChJVcN23SjDVc8mKshOskRVnjS5y3rRNLTJMVpBsMSitgiLO16SbJqeNVQH9/D6q07QP6wHNZgiECJFlxHmGD0aHgVBezehuMjZE3sODaOq0WQEXPEv54wq+A3mV1hGouUzrs8BMISTxJx9wG3u5NUcc/9ypDpN/aEFjwC6Yya67UXm/3rmppW1ZWteylLShNyOG0w5n7u3vyVyy3ezVZu7rIUG7SR5n1If1dtKmNzifmsiEZDxjIrvj8koWV3kZ2Ttiru1+26KjXTIWEfAYTyTJ0xxuJ29iPexgPMI1ombXkzsop+EGw2FyX3yM8lLSnQnj3MmPmrW8LrJONKyoRM2KXivW9iWyVnSl0LqmX/+OmjVpGQUo5aLIC5DLYhGRF1yk1VlkIb1NtaaoJP9g1X61oLSeRYMwgQqBVIgvft8yOip0fgWougGmHsKAsGBgLEx7B2i7SaMDZTVoXJ67yQZlrAcF/X4cTxGw1DFq6ONE9M8TYZeJWMFhMBTfEGG3G6mTWMiccvc8TuBxpxwJS8FiJqNjkZ2i4CncDcSkFN744OcqDxOMxqJyEJyynvJtVQzj4WDCQGX9gb/9BYo0eJrx2ExLxSDa9PV43ihHSc0T3sXDOjOmfaYzlI1gmNUdKzKtmWp4xURZyVLJqmy6/N3GtBRZShAvMp6WcQa/ATlf5paW/heZSW8b01KKIv/gMb2+vrk4XsIn2KrjRbY63nP4BVp+eS/iv4ALcflaOTKd7X5UZzXrKtU1DbKuzSpWYKtYXYqOibyXfVVmmHXtO1qLXI5f1i/WsgCyatL8WaF6tv//IgvpjdaSy/yjreV+oGSLZ5y/jcoty15tka6jm7wHStijI7m+XX7yH9p0gj19UV6tkh+QRNGKejdtF1uKxjE/pPDZTsRycFCn6AkafedMa+yGgpFfRLPxs1OQczxN4/6VP3xBZ3EEb/5G4NFfYl6aIE9b1GjCHNDY3T7MZkSKx0eKqOm8iPgJJBereS12Z8j83GKlMCj/Yyzd98QQWVH/zHse/wVC4Lep',\n",
       "  'file_directory': 'D:\\\\MultiModulRag\\\\docs',\n",
       "  'filename': 'NIPS-2017-attention-is-all-you-need-Paper.pdf'}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets again see some random index\n",
    "pdf_elements[10].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527495ff-0e84-400e-b6a6-982a5288f2f5",
   "metadata": {},
   "source": [
    "## Preprocess the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e35d92-78bc-46be-985e-6baba4830b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_md = \"data/uber_10q_march_2022.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "946d2081-9070-423b-99f0-ce260e9a6491",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/uber_10q_march_2022.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m md_elements = \u001b[43mpartition_md\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename_md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MultiModulRag\\venv\\Lib\\site-packages\\unstructured\\partition\\md.py:58\u001b[39m, in \u001b[36mpartition_md\u001b[39m\u001b[34m(filename, file, text, url, metadata_filename, metadata_last_modified, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m last_modified = get_last_modified_date(filename) \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     _, text = \u001b[43mread_txt_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m     _, text = read_txt_file(file=file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MultiModulRag\\venv\\Lib\\site-packages\\unstructured\\file_utils\\encoding.py:133\u001b[39m, in \u001b[36mread_txt_file\u001b[39m\u001b[34m(filename, file, encoding)\u001b[39m\n\u001b[32m    131\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m         formatted_encoding, file_text = \u001b[43mdetect_file_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m file:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m encoding:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MultiModulRag\\venv\\Lib\\site-packages\\unstructured\\file_utils\\encoding.py:67\u001b[39m, in \u001b[36mdetect_file_encoding\u001b[39m\u001b[34m(filename, file)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_file_encoding\u001b[39m(\n\u001b[32m     63\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m     file: Optional[Union[\u001b[38;5;28mbytes\u001b[39m, IO[\u001b[38;5;28mbytes\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     65\u001b[39m ) -> Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     68\u001b[39m             byte_data = f.read()\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m file:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/uber_10q_march_2022.md'"
     ]
    }
   ],
   "source": [
    "md_elements = partition_md(filename=filename_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9eee4f04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md_elements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# lets again see some random index\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmd_elements\u001b[49m[\u001b[32m33\u001b[39m].to_dict(), pdf_elements[\u001b[32m33\u001b[39m].to_dict()\n",
      "\u001b[31mNameError\u001b[39m: name 'md_elements' is not defined"
     ]
    }
   ],
   "source": [
    "# lets again see some random index\n",
    "md_elements[33].to_dict(), pdf_elements[33].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5533a29-62fe-432b-bfa0-499d4029fdbf",
   "metadata": {},
   "source": [
    "#### Let's still do some more exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b00b8c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md_elements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(pdf_elements), \u001b[38;5;28mlen\u001b[39m(\u001b[43mmd_elements\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'md_elements' is not defined"
     ]
    }
   ],
   "source": [
    "len(pdf_elements), len(md_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b739a36-8f61-46ac-861b-641f56b140f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = chunk_by_title(pdf_elements + md_elements) # you can play around with the chunk_by_title arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2df9e6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d69d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UncategorizedText',\n",
       " 'element_id': 'b0c5cfcf93a217591e27d5c97845f59b',\n",
       " 'text': '3 2 0 2',\n",
       " 'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "     732.8055555555557),\n",
       "    (45.388888888888886, 843.9166666666669),\n",
       "    (100.94444444444446, 843.9166666666669),\n",
       "    (100.94444444444446, 732.8055555555557)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-05-03T13:31:00',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'file_directory': 'data',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2789bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UncategorizedText',\n",
       " 'element_id': '07edc40df2508eb1259212408427c16f',\n",
       " 'text': '1 v 1 3 9 4 0 . 1 1 3 2 : v i X r a',\n",
       " 'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "     1218.8611111111109),\n",
       "    (45.388888888888886, 1680.25),\n",
       "    (100.94444444444446, 1680.25),\n",
       "    (100.94444444444446, 1218.8611111111109)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-05-03T13:31:00',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'parent_id': '4bff1bcde9e4a6e875fb8a8fc7b79e19',\n",
       "  'file_directory': 'data',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab0af605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': 'de7552d5-35e4-4f67-9e92-8bb73a59f958',\n",
       " 'text': '3 2 0 2\\n\\n1 v 1 3 9 4 0 . 1 1 3 2 : v i X r a\\n\\nGPT4All: An Ecosystem of Open Source Compressed Language Models\\n\\nYuvanesh Anand Nomic AI yuvanesh@nomic.ai\\n\\nZach Nussbaum Nomic AI zach@nomic.ai\\n\\nAdam Treat Nomic AI adam@nomic.ai\\n\\nAaron Miller Nomic AI aaron@nomic.ai\\n\\nRichard Guo Nomic AI richard@nomic.ai\\n\\nBen Schmidt Nomic AI ben@nomic.ai\\n\\nGPT4All Community Planet Earth\\n\\nBrandon Duderstadt Nomic AI brandon@nomic.ai\\n\\nAndriy Mulyar Nomic AI andriy@nomic.ai',\n",
       " 'metadata': {'file_directory': 'data',\n",
       "  'filename': 'gpt4all.pdf',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2024-05-03T13:31:00',\n",
       "  'page_number': 1,\n",
       "  'orig_elements': 'eJzlWNtuGzcQ/RVCz86W94uf6rRBUKBJg8YF2rqBwMvQWmAvwmqVRgny75292FZiubEL6MH1k3QOh1guz+FwZi8+LaCCGpp+WabFKVkEGlXMMTvhOTPKMeAmqeiMlSorFxYnZFFD75PvPcZ/WsS27VLZ+B42I678rt32yxWUl6seGS6Ewzkz/XeZ+hWyTCuJ7Lotm36Yd3EhVYGMEbyw707IDK0UhRsgo7Rwt/EUjsRis9v0UA9v8Kb8ANXbtY+w+IwDuaxgmcoOYt92uyFgXPo80vgaBu5y3UtfVcU65auhfrceh/x6XZXR92XbfDcPV7653PrL8Y0vFtBcLt6N7KZf1m0qcwnjXnLK5TOqnlFxzsSpYKeUDrPXOHPZbOsA3bATwyJ7+DDs1UIQTijhQ9TV439r8Nlw2XblR0jnQxxO+Fo1aiBFSVPmiloIjCvHGZfUSm4i0/nIqjHO7KTLjLWlBd/T6TYxzXjcyo1Md6OCDDmzEBM4kF6DNSoH622OJhgHzC32pWbkPWFEEEckSl7g/wFxcop8SX4nHfEPtoF30qYA3GfDldXeZ0s9c1qppDgP5mg24IwW6oRgxphO7xVWpjCj6lLYQhwixhn/aoMEPToANVxG1GmzXHdtwDBaSMsV+9/75OWbc3lWVafkrCEvYjttE2kz+WUNDXnbbrsI5Ie2Xnew2UAiP88rJ6/aBNVm30PnZV/BQd+ADMxkIVQU3KJ4uCZGM+VWGpZkOppvmGOFPSGCqsk3M5ZMz+nEyILdxlP8E04ef2zf+wY2KzSFbxJ53dZlJGc/kd3Mf98MTOHLe8lvWbBRM9BeOOYd2KBUoMZb6xE5ejT5FV4Xbk/+GV/LbYwqzG385OX/08cVeb3dbILf1jfqf0T6YconlDnpQH1STAtnEhfGgzHORO+th6Mpb6384uDP+FppNtQJ5gDx5LU/S74m5x34/kZ41Kd+4JF3jnPnTRSSowmC8CxIaWjikguw+ngZn1M7lAY3KX8mJBaEeioNJCvoAeIe0t9ZK3AlrXyM3vjmCf3CG75rG/KqrCro9twxsAft8dp3Hb7Ke7iroExRUxtjFJCUMkZ4pXgMwdKYXPL5eDbhxo0esKwQY0E5YWxrCjndFLLQt/EU/4Szw69lXPkukZfb9sYA3UQ+LENE4SRlnGNu4DYGEbSxQoHlWeug1fFqQsPZWARcST9j5cSUMBwfO4ev8T2kv7uTwPfUj9Eb3zyf+954PvQLcVXjzt94I8B/TA1UgWE6K4vWdABRS66jsYplllJO8ng3CLVubAquDHJFKCVnAq07fIa4RTz59DA3k0O/WG+bst+RN7g46MkL3+F23ycv4EkxFMsyzrISFH8jzykYrfEM4SOP+IGQiuEK0EpMos7YaFvQMU9QdwhP8U9Y8+cdtohYFvy4TdBtUJj+ry3nzOzlgCniYfcDliGGqcS48Ci+SdRSE7F6DNpmF7w9mg+cscNZvvbBjAfd5VRQ4oVADxD3cMKdNwQ2xoo/Rqt887h+UT82qSt35NW22vnua5f4cfA+l8W7fwDSHD2i'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c63851b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mchunk_by_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0melements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[Element]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcombine_text_under_n_chars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minclude_orig_elements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[bool]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_characters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultipage_sections\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[bool]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnew_after_n_chars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverlap\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverlap_all\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[bool]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'list[Element]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mchunk_by_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0melements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcombine_text_under_n_chars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minclude_orig_elements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_characters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultipage_sections\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnew_after_n_chars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverlap\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverlap_all\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Uses title elements to identify sections within the document for chunking.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Splits off into a new CompositeElement when a title is detected or if metadata changes, which\u001b[0m\n",
      "\u001b[0;34m    happens when page numbers or sections change. Cuts off sections once they have exceeded a\u001b[0m\n",
      "\u001b[0;34m    character length of max_characters.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    elements\u001b[0m\n",
      "\u001b[0;34m        A list of unstructured elements. Usually the output of a partition function.\u001b[0m\n",
      "\u001b[0;34m    combine_text_under_n_chars\u001b[0m\n",
      "\u001b[0;34m        Combines elements (for example a series of titles) until a section reaches a length of\u001b[0m\n",
      "\u001b[0;34m        n characters. Defaults to `max_characters` which combines chunks whenever space allows.\u001b[0m\n",
      "\u001b[0;34m        Specifying 0 for this argument suppresses combining of small chunks. Note this value is\u001b[0m\n",
      "\u001b[0;34m        \"capped\" at the `new_after_n_chars` value since a value higher than that would not change\u001b[0m\n",
      "\u001b[0;34m        this parameter's effect.\u001b[0m\n",
      "\u001b[0;34m    include_orig_elements\u001b[0m\n",
      "\u001b[0;34m        When `True` (default), add elements from pre-chunk to the `.metadata.orig_elements` field\u001b[0m\n",
      "\u001b[0;34m        of the chunk(s) formed from that pre-chunk. Among other things, this allows access to\u001b[0m\n",
      "\u001b[0;34m        original-element metadata that cannot be consolidated and is dropped in the course of\u001b[0m\n",
      "\u001b[0;34m        chunking.\u001b[0m\n",
      "\u001b[0;34m    max_characters\u001b[0m\n",
      "\u001b[0;34m        Chunks elements text and text_as_html (if present) into chunks of length\u001b[0m\n",
      "\u001b[0;34m        n characters (hard max)\u001b[0m\n",
      "\u001b[0;34m    multipage_sections\u001b[0m\n",
      "\u001b[0;34m        If True, sections can span multiple pages. Defaults to True.\u001b[0m\n",
      "\u001b[0;34m    new_after_n_chars\u001b[0m\n",
      "\u001b[0;34m        Cuts off new sections once they reach a length of n characters (soft max). Defaults to\u001b[0m\n",
      "\u001b[0;34m        `max_characters` when not specified, which effectively disables any soft window.\u001b[0m\n",
      "\u001b[0;34m        Specifying 0 for this argument causes each element to appear in a chunk by itself (although\u001b[0m\n",
      "\u001b[0;34m        an element with text longer than `max_characters` will be still be split into two or more\u001b[0m\n",
      "\u001b[0;34m        chunks).\u001b[0m\n",
      "\u001b[0;34m    overlap\u001b[0m\n",
      "\u001b[0;34m        Specifies the length of a string (\"tail\") to be drawn from each chunk and prefixed to the\u001b[0m\n",
      "\u001b[0;34m        next chunk as a context-preserving mechanism. By default, this only applies to split-chunks\u001b[0m\n",
      "\u001b[0;34m        where an oversized element is divided into multiple chunks by text-splitting.\u001b[0m\n",
      "\u001b[0;34m    overlap_all\u001b[0m\n",
      "\u001b[0;34m        Default: `False`. When `True`, apply overlap between \"normal\" chunks formed from whole\u001b[0m\n",
      "\u001b[0;34m        elements and not subject to text-splitting. Use this with caution as it entails a certain\u001b[0m\n",
      "\u001b[0;34m        level of \"pollution\" of otherwise clean semantic chunk boundaries.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ByTitleChunkingOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcombine_text_under_n_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombine_text_under_n_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minclude_orig_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_orig_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmultipage_sections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultipage_sections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnew_after_n_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_after_n_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moverlap_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlap_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_chunk_by_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/yt-code/youtube-stuffs/data-cleaning/.venv/lib/python3.11/site-packages/unstructured/chunking/title.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "chunk_by_title??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5def9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_elements = chunk_by_title((pdf_elements + md_elements),combine_text_under_n_chars=100,max_characters=3000)\n",
    "#len(chunk_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d0ac3",
   "metadata": {},
   "source": [
    "## Load the Documents into the Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a87e5924-6c42-47ab-8cd1-2c22caed71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9af0f348-0697-4bed-8f97-a0ee03475ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for element in elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    del metadata[\"languages\"]\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "187514ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbd8d9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5502d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43ce7dc4-a23f-4024-b647-1eae469efc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|| 5/5 [00:00<00:00, 78251.94it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2bc691d-18e8-4833-9009-e13f7fa13e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take some time, patience is the key :)\n",
    "vectorstore = Qdrant.from_documents(documents=documents,\n",
    "                                    embedding = embeddings,\n",
    "                                    url = qdrant_url,\n",
    "                                    collection_name=\"rag\",\n",
    "                                    api_key=qdrant_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a775b466-16af-4bf1-94d5-c96563ce50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aadbc2",
   "metadata": {},
   "source": [
    "## Let's create RAG (Qdrant, Groq, LangChain, Llama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b3a5fa6-7169-4f1f-aabd-15eec4da8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import chat_history_aware_retriever\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "238ea8c4-c099-490a-877c-2050b65fd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about the GPT4All paper and Quarterly Report Pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934 for the quarterly period ended March 31, 2022.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42096f06-ae93-4d5d-acb6-02b760745b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0,model_name=\"llama3-8b-8192\")\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "qa_chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator_chain,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9329374-1a3f-44aa-8cd0-14a6d8bcae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The net loss including non-controlling interests of Uber in 2021 was $(122) million.\\nSOURCES: uber_10q_march_2022.md'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke({\n",
    "    \"question\": \"What was the net loss including non-controlling interests of Uber in 2021\", #line 533\n",
    "    \"chat_history\": []\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2f3d9ab-9cb4-4b64-8ed6-db3467f2a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid search in action\n",
    "filter_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1, \"filter\": {\"source\": \"gpt4all.pdf\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebca3607-5cc0-46e3-9f1e-ef60955d3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_chain = ConversationalRetrievalChain(\n",
    "    retriever=filter_retriever,\n",
    "    question_generator=question_generator_chain,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67c0ff39-291e-4cd1-9aef-b2db960a728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help!\\n\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nFINAL ANSWER: GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications.\\nSOURCES: gpt4all.pdf\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_chain.invoke({\n",
    "    \"question\": \"How was GPT4All-Snoozy developed ?\",\n",
    "    \"chat_history\": [],\n",
    "    \"filter\": filter,\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64114f95-ca0e-4de8-a335-fa8a4849da96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
